{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonyw54/ml-2/blob/main/Tony_Waterman_Task0_Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3I6fuLcLJ6b"
      },
      "source": [
        "Create a benchmark analysis with different algorithms and feature extractors.\n",
        "\n",
        "Dataset: Fetch 20 Newsgroups​\n",
        "\n",
        "Feature Extractors:\n",
        "\n",
        "1. CountVectorizer\n",
        "2. Word2Vec\n",
        "3. Doc2Vec\n",
        "4. TfidfTransformer\n",
        "\n",
        "Algorithms:\n",
        "\n",
        "* Multinomial Naïve Bayes\n",
        "* Logistic Regression\n",
        "* Support Vector Machines\n",
        "* Decision Trees\n",
        "\n",
        "Benchmark all the possible above configurations and choose the best algorithm and feature extractor amongst all configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "UvWQeybJ2vQ5"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy  # For preprocessing\n",
        "import nltk  # For preprocessing\n",
        "import re\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import Doc2Vec\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8LI0qvuLkpu"
      },
      "outputs": [],
      "source": [
        "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
        "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrWEEE25n00q"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isqcu1GEppEw"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
        "\n",
        "# Adapted from https://www.kaggle.com/code/pierremegret/gensim-word2vec-tutorial\n",
        "def cleaning(doc):\n",
        "    # Lemmatizes and removes stopwords\n",
        "    # doc needs to be a spacy Doc object\n",
        "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
        "    return ' '.join(txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx-GOKzWqHLA",
        "outputId": "9f9265c9-d5ca-4b19-bae5-407de6cdadab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time to clean up training data: 4.91 mins\n",
            "Time to clean up test data: 2.82 mins\n"
          ]
        }
      ],
      "source": [
        "# Clean up training data\n",
        "X_train_brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in twenty_train.data)\n",
        "t = time()\n",
        "X_train = [cleaning(doc) for doc in nlp.pipe(X_train_brief_cleaning, batch_size=1000)]\n",
        "print('Time to clean up training data: {} mins'.format(round((time() - t) / 60, 2)))\n",
        "\n",
        "# Clean up testing data\n",
        "X_test_brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in twenty_test.data)\n",
        "t = time()\n",
        "X_test = [cleaning(doc) for doc in nlp.pipe(X_test_brief_cleaning, batch_size=1000)]\n",
        "print('Time to clean up test data: {} mins'.format(round((time() - t) / 60, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG4KAyCoTTS0"
      },
      "source": [
        "# Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svIrl3d5cIW2"
      },
      "outputs": [],
      "source": [
        "vect = CountVectorizer()\n",
        "X_train_cv = vect.fit_transform(X_train)\n",
        "X_test_cv = vect.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7TxflSuTeT-"
      },
      "source": [
        "#### Multinomial Naïve Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVcBehp6TpbU",
        "outputId": "0f3724f2-a2c9-4dd6-bf4b-305816b3090c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8037705788635157"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nb = MultinomialNB()\n",
        "y_pred = nb.fit(X_train_cv, twenty_train.target).predict(X_test_cv)\n",
        "nb.score(X_test_cv, twenty_test.target)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRY5ZsI2c-Ce"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyxejjXIc9XI",
        "outputId": "c7ad43c8-33bd-4d68-ee6e-b11b93625470"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8027084439723845"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr = LogisticRegression(max_iter=2000)\n",
        "y_pred = lr.fit(X_train_cv, twenty_train.target).predict(X_test_cv)\n",
        "lr.score(X_test_cv, twenty_test.target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRyebhoUf1WI"
      },
      "source": [
        "#### Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EUaQWuBwTRdO",
        "outputId": "55ec5f65-924f-43a8-dcd4-378a3fc59cbf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.10143388210302709"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "svc = SVC()\n",
        "y_pred = svc.fit(X_train_cv, twenty_train.target).predict(X_test_cv)\n",
        "svc.score(X_test_cv, twenty_test.target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV2Ei2DRhgwE"
      },
      "source": [
        "#### Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "__5TPqb2TYg8",
        "outputId": "2baa7029-a3d6-48a2-9df4-79fe852acf9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.581651619755709"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "y_pred = dt.fit(X_train_cv, twenty_train.target).predict(X_test_cv)\n",
        "dt.score(X_test_cv, twenty_test.target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apvBtnGyiD5_"
      },
      "source": [
        "# Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gD0uUriEiDZC"
      },
      "outputs": [],
      "source": [
        "X_train_split = [sentence.split() for sentence in X_train]\n",
        "X_test_split = [sentence.split() for sentence in X_test]\n",
        "\n",
        "w2v = Word2Vec(sentences=X_train_split, min_count=5, workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v.wv.most_similar('love')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG2Ufl2BGRsJ",
        "outputId": "51d923bb-fd0a-4ca1-9529-15b41ad3c32d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bless', 0.8133929371833801),\n",
              " ('satan', 0.8093088269233704),\n",
              " ('sinner', 0.8065330982208252),\n",
              " ('heaven', 0.8026398420333862),\n",
              " ('hell', 0.7991043925285339),\n",
              " ('praise', 0.7911373972892761),\n",
              " ('merciful', 0.7892584800720215),\n",
              " ('forgive', 0.7878407835960388),\n",
              " ('christ', 0.7860519886016846),\n",
              " ('sad', 0.7761499285697937)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYwzKm8zC0EQ86gV1DrBl3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}